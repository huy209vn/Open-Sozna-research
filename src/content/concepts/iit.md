---
title: "IIT (Integrated Information Theory)"
---

Honestly? I don't fully understand IIT. I've tried reading Tononi's papers and they're dense in that specific academic way — every sentence compressed, every term pre-defined by reference to another paper you haven't read.

But here's what I *think* I get:

IIT tries to assign a number — **phi (Φ)** — to consciousness. The intuition is something like: *how much more is the system than the sum of its parts?* If you have a bunch of independent things doing their own thing, phi is low. If they're integrated into something unified, phi is high.

A camera sensor: million pixels, independent. Low phi. Your brain: everything talking to everything, bound together into one experience. High phi.

**But here's my problem:** No one can actually calculate phi for a real brain. It's computationally intractable. So you have this theory that claims to measure consciousness, but you can't use it to measure anything interesting.

And even if you *could* calculate it... then what? You'd know this system has phi=3.2 and that one has phi=5.1. Okay. But does that tell you **how to build** a conscious system? Does it tell you what makes consciousness *work*, not just *exist*?

IIT feels like it's measuring a symptom. Like taking the temperature of a patient and declaring you understand medicine. Yeah, fever tells you something's wrong. But what's the mechanism? What's the process? How do you *fix* it or *build* it?

For living systems — for actually understanding how minds work, how they become human, how they develop and change — phi feels underwhelming. It's one number. Consciousness isn't one thing. It's intelligence, emotion, memory, agency, a sense of self, all developing over time, all interdependent.

Maybe I'm missing something. Probably am. But IIT doesn't feel like the framework that's going to help me build what I'm trying to build.
