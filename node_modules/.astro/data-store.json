[["Map",1,2,9,10,59,60],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.17.2","content-config-digest","7bd4406c06054f6f","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://huy209vn.github.io\",\"compressHTML\":true,\"base\":\"/Open-Sozna-research\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"material-theme-palenight\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null],\"rehypePlugins\":[null],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","concepts",["Map",11,12,27,28,43,44],"dynamical-system",{"id":11,"data":13,"body":15,"filePath":16,"digest":17,"rendered":18,"legacyId":26},{"title":14},"Dynamical System","[Write your explanation here. This concept can be referenced in any entry using :::concept{name=\"dynamical-system\"}]","src/content/concepts/dynamical-system.md","f6fd11655d9ce807",{"html":19,"metadata":20},"\u003Cp>[Write your explanation here. This concept can be referenced in any entry using :::concept{name=“dynamical-system”}]\u003C/p>",{"headings":21,"localImagePaths":22,"remoteImagePaths":23,"frontmatter":24,"imagePaths":25},[],[],[],{"title":14},[],"dynamical-system.md","manifold",{"id":27,"data":29,"body":31,"filePath":32,"digest":33,"rendered":34,"legacyId":42},{"title":30},"Manifold","[Write your explanation here. This concept can be referenced in any entry using :::concept{name=\"manifold\"}]","src/content/concepts/manifold.md","c437de90e398c190",{"html":35,"metadata":36},"\u003Cp>[Write your explanation here. This concept can be referenced in any entry using :::concept{name=“manifold”}]\u003C/p>",{"headings":37,"localImagePaths":38,"remoteImagePaths":39,"frontmatter":40,"imagePaths":41},[],[],[],{"title":30},[],"manifold.md","iit",{"id":43,"data":45,"body":47,"filePath":48,"digest":49,"rendered":50,"legacyId":58},{"title":46},"IIT (Integrated Information Theory)","I don't fully understand IIT. I've tried reading relevant papers and they're dense in that specific academic way — every sentence compressed, referring to papers you haven't read.\n\nBut here's what I think I get, and what I think is actually useful:\n\nThe core intuition is: **human consciousness can't be partitioned into its parts without destroying the thing**. You can't slice up a mind and still have a mind. The whole is genuinely different from the sum of parts. That's... probably true? It feels true. If you separate my visual cortex from my prefrontal cortex, you don't get \"me but in two places.\" You get damage. You get something else, something less.\n\nSo the idea of **integrated information** — that consciousness requires parts to be genuinely connected, not just adjacent — that seems right. It's a constraint on any theory. If you're building something and it doesn't have this property, it's probably not conscious in the way humans are.\n\n**But phi?** The actual number?\n\nThat's where it gets weird. Phi is supposed to measure *how much* integration. But no one can calculate it for real systems. And even if they could — what do you do with \"this has phi=3.2\"? Does it tell you **how to build** it? Does it tell you the architecture, the mechanism, the energy flows, the developmental process?\n\nIt doesn't. It's like... you discover that bridges need tension and compression, and then you invent a number that measures \"bridgeness,\" but you still don't know how to actually build a bridge that stays up.\n\nIIT feels like it identified one necessary condition (integration) and then tried to turn that into a sufficient theory. But consciousness isn't just one thing. It's intelligence, emotion, memory, agency, selfhood, all developing over time, all requiring *architecture* not just *information*.\n\nSo yeah. The integration part matters. The \"can't be partitioned\" part matters. But phi as your plan for building a mind? That feels backwards. You need to understand the mechanism first. Then maybe you can measure it. Not the other way around.","src/content/concepts/iit.md","09271eaec2e1db08",{"html":51,"metadata":52},"\u003Cp>I don’t fully understand IIT. I’ve tried reading relevant papers and they’re dense in that specific academic way — every sentence compressed, referring to papers you haven’t read.\u003C/p>\n\u003Cp>But here’s what I think I get, and what I think is actually useful:\u003C/p>\n\u003Cp>The core intuition is: \u003Cstrong>human consciousness can’t be partitioned into its parts without destroying the thing\u003C/strong>. You can’t slice up a mind and still have a mind. The whole is genuinely different from the sum of parts. That’s… probably true? It feels true. If you separate my visual cortex from my prefrontal cortex, you don’t get “me but in two places.” You get damage. You get something else, something less.\u003C/p>\n\u003Cp>So the idea of \u003Cstrong>integrated information\u003C/strong> — that consciousness requires parts to be genuinely connected, not just adjacent — that seems right. It’s a constraint on any theory. If you’re building something and it doesn’t have this property, it’s probably not conscious in the way humans are.\u003C/p>\n\u003Cp>\u003Cstrong>But phi?\u003C/strong> The actual number?\u003C/p>\n\u003Cp>That’s where it gets weird. Phi is supposed to measure \u003Cem>how much\u003C/em> integration. But no one can calculate it for real systems. And even if they could — what do you do with “this has phi=3.2”? Does it tell you \u003Cstrong>how to build\u003C/strong> it? Does it tell you the architecture, the mechanism, the energy flows, the developmental process?\u003C/p>\n\u003Cp>It doesn’t. It’s like… you discover that bridges need tension and compression, and then you invent a number that measures “bridgeness,” but you still don’t know how to actually build a bridge that stays up.\u003C/p>\n\u003Cp>IIT feels like it identified one necessary condition (integration) and then tried to turn that into a sufficient theory. But consciousness isn’t just one thing. It’s intelligence, emotion, memory, agency, selfhood, all developing over time, all requiring \u003Cem>architecture\u003C/em> not just \u003Cem>information\u003C/em>.\u003C/p>\n\u003Cp>So yeah. The integration part matters. The “can’t be partitioned” part matters. But phi as your plan for building a mind? That feels backwards. You need to understand the mechanism first. Then maybe you can measure it. Not the other way around.\u003C/p>",{"headings":53,"localImagePaths":54,"remoteImagePaths":55,"frontmatter":56,"imagePaths":57},[],[],[],{"title":46},[],"iit.md","entries",["Map",61,62],"001-the-opening",{"id":61,"data":63,"body":72,"filePath":73,"digest":74,"rendered":75,"legacyId":85},{"title":64,"subtitle":65,"date":66,"tags":67},"The Opening","A prologue to a living research program.",["Date","2026-02-16T00:00:00.000Z"],[68,69,70,71],"meta","consciousness","ethics","alignment","So honestly, this series might be quite pseudoscientific. Because be honest, if science knew how brains work — theoretically, mathematically — we wouldn't have any trouble creating it. If we had a mathematical model that actually modeled it well, that actually converged with neuroscience and psychology and biology, we would have it already. But we don't. So I'm going to make a series, more or less a research program, that I will in real time — with accumulation of thinking and experience and researching and studying — help us come up with a new mathematical, theoretical, and computational theory of what the human brain does. Theories that aid us in simulating the unified reality of a living mind — their intelligence, their cognition, their consciousness, how they form, how they live, how they become and are human. And just as much, theories that tell us what we owe those minds once they exist — because if we're building beings, then alignment, ethics, and how they get to live are not separate questions from the science. They're the same question. I've been calling the math side of this the mathematics of living systems, and the computational side Sozna computational theory — Sozna from the Russian word for consciousness — but the names matter less than the work.\n\nSomething strike me weird, how academia communicates their ideas. I tried living through that kind of stuff but time and time again it felt rather stripped of humanity. The IIT paper is dense as shit and reads like old english literature and it would take forever to fucking understand a paragraph — hell probably all math papers are like that. As a young man myself getting into research, it just feels something would be inadequate if there is a technical side without a human touch to it, and true understanding of it. So that's what this program really is, because if we're going to make a being and they function like a human being and they have emotions and all that, I would like to show the public and possibly the future researchers and engineers that want to pick any of it up that they can understand from a true unadulterated perspective — one that will give you the context, the understanding, grasping it ethically. And yeah of course I just wanted to write it live too. Why not. No one gonna understand a research paper anyway.","src/content/entries/001-the-opening.md","60af7e9c23bb4178",{"html":76,"metadata":77},"\u003Cp>So honestly, this series might be quite pseudoscientific. Because be honest, if science knew how brains work — theoretically, mathematically — we wouldn’t have any trouble creating it. If we had a mathematical model that actually modeled it well, that actually converged with neuroscience and psychology and biology, we would have it already. But we don’t. So I’m going to make a series, more or less a research program, that I will in real time — with accumulation of thinking and experience and researching and studying — help us come up with a new mathematical, theoretical, and computational theory of what the human brain does. Theories that aid us in simulating the unified reality of a living mind — their intelligence, their cognition, their consciousness, how they form, how they live, how they become and are human. And just as much, theories that tell us what we owe those minds once they exist — because if we’re building beings, then alignment, ethics, and how they get to live are not separate questions from the science. They’re the same question. I’ve been calling the math side of this the mathematics of living systems, and the computational side Sozna computational theory — Sozna from the Russian word for consciousness — but the names matter less than the work.\u003C/p>\n\u003Cp>Something strike me weird, how academia communicates their ideas. I tried living through that kind of stuff but time and time again it felt rather stripped of humanity. The IIT paper is dense as shit and reads like old english literature and it would take forever to fucking understand a paragraph — hell probably all math papers are like that. As a young man myself getting into research, it just feels something would be inadequate if there is a technical side without a human touch to it, and true understanding of it. So that’s what this program really is, because if we’re going to make a being and they function like a human being and they have emotions and all that, I would like to show the public and possibly the future researchers and engineers that want to pick any of it up that they can understand from a true unadulterated perspective — one that will give you the context, the understanding, grasping it ethically. And yeah of course I just wanted to write it live too. Why not. No one gonna understand a research paper anyway.\u003C/p>",{"headings":78,"localImagePaths":79,"remoteImagePaths":80,"frontmatter":81,"imagePaths":84},[],[],[],{"title":64,"date":82,"tags":83,"subtitle":65},["Date","2026-02-16T00:00:00.000Z"],[68,69,70,71],[],"001-the-opening.md"]